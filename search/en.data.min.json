[{"id":0,"href":"/usage/getting-started/","title":"Getting Started","parent":"Usage","content":"   Installation Architectural Fundamentals Accessing Database Whats next?      Installation     Before you can use Redrock Postgres you need to install it, of course. It is possible that PostgreSQL is already installed at your site, either because it was included in your operating system distribution or because the system administrator already installed it. If that is the case, you should obtain information from the operating system documentation or your system administrator about how to access PostgreSQL.\nIf you are not sure whether PostgreSQL is already available or whether you can use it for your experimentation then you can install it yourself. Doing so is not hard and it can be a good exercise.\nIf you are installing Redrock Postgres yourself, then refer to Installation Guide for instructions on installation, and return to this guide when the installation is complete. Be sure to follow closely the section about setting up the appropriate environment variables.\nIf your site administrator has not set things up in the default way, you might have some more work to do. For example, if the database server machine is a remote machine, you will need to set the PGHOST environment variable to the name of the database server machine. The environment variable PGPORT might also have to be set. The bottom line is this: if you try to start an application program and it complains that it cannot connect to the database, you should consult your site administrator or, if that is you, the documentation to make sure that your environment is properly set up. If you did not understand the preceding paragraph then read the next section.\nArchitectural Fundamentals     Before we proceed, you should understand the basic PostgreSQL system architecture. Understanding how the parts of PostgreSQL interact will make this chapter somewhat clearer.\nIn database jargon, PostgreSQL uses a client/server model. A PostgreSQL session consists of the following cooperating processes (programs):\n A server process, which manages the database files, accepts connections to the database from client applications, and performs database actions on behalf of the clients. The database server program is called postgres. The user\u0026rsquo;s client (frontend) application that wants to perform database operations. Client applications can be very diverse in nature: a client could be a text-oriented tool, a graphical application, a web server that accesses the database to display web pages, or a specialized database maintenance tool. Some client applications are supplied with the PostgreSQL distribution; most are developed by users.  As is typical of client/server applications, the client and the server can be on different hosts. In that case they communicate over a TCP/IP network connection. You should keep this in mind, because the files that can be accessed on a client machine might not be accessible (or might only be accessible using a different file name) on the database server machine.\nThe PostgreSQL server can handle multiple concurrent connections from clients. To achieve this it starts (“forks”) a new process for each connection. From that point on, the client and the new server process communicate without intervention by the original postgres process. Thus, the supervisor server process is always running, waiting for client connections, whereas client and associated server processes come and go. (All of this is of course invisible to the user. We only mention it here for completeness.)\nAccessing Database     Once you have created a database, you can access it by:\n Running the PostgreSQL interactive terminal program, called psql, which allows you to interactively enter, edit, and execute SQL commands. Using an existing graphical frontend tool like pgAdmin or an office suite with ODBC or JDBC support to create and manipulate a database. These possibilities are not covered in this tutorial. Writing a custom application, using one of the several available language bindings. These possibilities are discussed further in Part IV.  You probably want to start up psql to try the examples in this tutorial. It can be activated for the postgres database by typing the command:\n$ psql postgres If you do not supply the database name then it will default to your user account name.\nIn psql, you will be greeted with the following message:\npsql (12.1) Type \u0026#34;help\u0026#34; for help. postgres=\u0026gt; The last line could also be:\npostgres=# That would mean you are a database superuser, which is most likely the case if you installed the PostgreSQL instance yourself. Being a superuser means that you are not subject to access controls. For the purposes of this tutorial that is not important.\nThe last line printed out by psql is the prompt, and it indicates that psql is listening to you and that you can type SQL queries into a work space maintained by psql. Try out these commands:\npostgres=\u0026gt; SELECT version(); version ------------------------------------------------------------------------------------------ PostgreSQL 12.1 on x86_64-pc-linux-gnu, compiled by gcc (Debian 4.9.2-10) 4.9.2, 64-bit (1 row) postgres=\u0026gt; SELECT current_date; date ------------ 2016-01-07 (1 row) postgres=\u0026gt; SELECT 2 + 2; ?column? ---------- 4 (1 row) The psql program has a number of internal commands that are not SQL commands. They begin with the backslash character, “\\”. For example, you can get help on the syntax of various PostgreSQL SQL commands by typing:\npostgres=\u0026gt; \\h To get out of psql, type:\npostgres=\u0026gt; \\q and psql will quit and return you to your command shell. (For more internal commands, type \\? at the psql prompt.) The full capabilities of psql are documented in psql. In this tutorial we will not use these features explicitly, but you can use them yourself when it is helpful.\nWhats next?     There are a lot more things to discover. To get more information, please refer to PostgreSQL Documentation.\n"},{"id":1,"href":"/installation/windows/","title":"Installing on Windows","parent":"Installation","content":"To perform an installation using the graphical installation wizard, you must have superuser or administrator privileges.\nThe following section walks you through installing PostgreSQL on a Windows host.\nTo start the installation wizard, assume sufficient privileges and double-click the installer icon; if prompted, provide a password.\nNote that in some versions of Windows, to invoke the installer with Administrator privileges, you need to right-click on the installer icon and select Run as Administrator from the context menu.\nThe Redrock 12 Setup Welcome window opens. Click Next to continue.\n    Fig. 1: The Redrock 12 Setup Welcome dialog    The Choose Install Location window opens. Accept the default installation directory, or specify an alternate location and click Next to continue.\n    Fig. 2: Choose Install Location dialog    Click Next to continue.\nThe Choose Data Directory window opens. Accept the default location or specify the name of the alternate directory in which you wish to store the data files.\n    Fig. 3: Choose Data Directory dialog    Click Next to continue.\nThe Server Options window opens.\n    Fig. 4: The Server Options dialog    PostgreSQL uses the Port field to specify the port number on which the server should listen. The default listener port is 5432.\nUse the Locale field to specify the locale that will be used by the new database cluster. The Default is the operating system locale.\nUse the Superuser field to specify the database superuser name. The default superuser name is postgres.\nUse the Password field to specify the database superuser password. The specified password should conform to enough complexities. After entering a password in the Password field, and confirming the password in the Retype Password field.\nClick Next to continue.\n    Fig. 5: Setting Configuration Parameters dialog    The Setting Configuration Parameters dialog will guides you to optimize server performance by setting some important configuration parameters. Maybe you can let the installer tune configuration parameters automatically, and click Next to continue.\n    Fig. 6: The Choose Start Menu Folder    During the installation, the setup wizard confirms the installation progress of PostgreSQL via a series of progress bars.\n    Fig. 7: The Installing dialog    When the Completing Redrock 12 Setup window appears, Congratulations! Click Finish to complete the PostgreSQL installation.\n    Fig. 8: Completing Redrock 12 Setup    "},{"id":2,"href":"/usage/","title":"Usage","parent":"Welcome to Redrock Documentation","content":""},{"id":3,"href":"/installation/","title":"Installation","parent":"Welcome to Redrock Documentation","content":""},{"id":4,"href":"/features/","title":"Features","parent":"Welcome to Redrock Documentation","content":""},{"id":5,"href":"/installation/redhat/","title":"Installing on Red Hat","parent":"Installation","content":"   Install Packages  Prerequisite Install Redrock Postgres   Post-installation commands  Data Directory Change Data Directory Initialize Startup   Control service After installation      Install Packages     Prerequisite     Log in to the host with your root account, and run the following commands to query installed packages, make sure none postgresql related packages already installed:\n# rpm -qa | grep postgresql Install Redrock Postgres     Download the Redrock Postgres Package for Red Hat or CentOS, and run the following commands to install:\n# tar xf redrock-12.1-1.el8.x86_64-bundle.tar # cd redrock-12.1-1.el8.x86_64-bundle # rpm -ivh redrock-12.1-1.el8.x86_64.rpm redrock-libs-12.1-1.el8.x86_64.rpm redrock-server-12.1-1.el8.x86_64.rpm Other packages can be installed according to your needs.\nPost-installation commands     After installing the packages, a database needs to be initialized and configured.\nIn the commands below, the value of version includes the major version of PostgreSQL, e.g., 12\nData Directory     The PostgreSQL data directory contains all of the data files for the database. The variable PGDATA is used to reference this directory.\nThe default data directory is:\n/var/lib/pgsql/\u0026lt;version\u0026gt;/data For example:\n/var/lib/pgsql/12/data Change Data Directory     If you do not want to use the default data directory, you can go to a custom mount point (eg: /u01) and create a folder pgdata with postgres permissions:\n# cd /u01 # mkdir pgdata # chown postgres:postgres pgdata Then, edit the postgresql service:\n# systemctl edit postgresql-12.service Go to the custom mount point that has the majority of the disk space, copy and paste the following into that file:\n[Service] Environment=PGDATA=/u01/pgdata Initialize     The first command (only needed once) is to initialize the database in PGDATA.\nIf the previous command did not work, try directly calling the setup binary, located in a similar naming scheme:\n# /usr/pgsql-\u0026lt;version\u0026gt;/bin/postgresql-\u0026lt;version\u0026gt;-setup initdb For versions 12, use:\n# /usr/pgsql-12/bin/postgresql-12-setup initdb Startup     If you want PostgreSQL to start automatically when the OS starts, do the following:\n# systemctl enable postgresql-12.service Control service     To control the database service, use:\n# systemctl \u0026lt;command\u0026gt; postgresql-12.service where command can be:\n enable : enable automatical start start : start the database stop : stop the database restart : stop/start the database; used to read changes to core configuration files reload : reload configuration files while keeping database running  E.g. to control version 12 database service, use:\n# systemctl enable postgresql-12.service # systemctl start postgresql-12.service After installation     Modify the pg_hba.conf file in data directory to define what authentication method should be used from all networks to the PostgreSQL server and modify the localhost authentication method (change from indent to md5 and change from localhost to accept all incoming requests). Find the lines below:\n# IPv4 local connections: host all all 127.0.0.1/32 ident And change it to:\n# IPv4 local connections: host all all 0.0.0.0/0 md5 Modify the postgresql.conf file in data directory to allow connections from all hosts by uncommenting the following line and adding an * instead of localhost:\nlisten_addresses = \u0026#39;*\u0026#39; Restart the database service to reload configurations:\n# systemctl restart postgresql-12.service In a production environment, you should also set up TLS-secured communication, and you should consider setting up data replication or snapshot-based backups. Consult the PostgreSQL online manual for these settings.\n"},{"id":6,"href":"/advanced/","title":"Advanced","parent":"Welcome to Redrock Documentation","content":""},{"id":7,"href":"/usage/configuration/","title":"Configuration","parent":"Usage","content":"Overview of all available server configuration options provided by the database.\n   Automatic Analyzing Run-time Statistics      Automatic Analyzing     These settings control the behavior of the autoanalyze feature. Refer to Section 24.1.6 for more information. Note that many of these settings can be overridden on a per-table basis; see Storage Parameters.\n  autoanalyze (boolean)\nControls whether the server should run the autoanalyze launcher daemon. This is on by default; however, track_counts must also be enabled for autoanalyze to work. This parameter can only be set in the postgresql.conf file or on the server command line; however, autoanalyzing can be disabled for individual tables by changing table storage parameters.\n  log_autoanalyze_min_duration (integer)\nCauses each action executed by autoanalyze to be logged if it ran for at least the specified amount of time. Setting this to zero logs all autoanalyze actions. -1 (the default) disables logging autoanalyze actions. If this value is specified without units, it is taken as milliseconds. For example, if you set this to 250ms then all automatic analyzes that run 250ms or longer will be logged. In addition, when this parameter is set to any value other than -1, a message will be logged if an autoanalyze action is skipped due to a conflicting lock or a concurrently dropped relation. Enabling this parameter can be helpful in tracking autoanalyze activity. This parameter can only be set in the postgresql.conf file or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.\n  autoanalyze_max_workers (integer)\nSpecifies the maximum number of autoanalyze processes (other than the autoanalyze launcher) that may be running at any one time. The default is three. This parameter can only be set at server start.\n  autoanalyze_naptime (integer)\nSpecifies the minimum delay between autoanalyze runs on any given database. In each round the daemon examines the database and issues ANALYZE commands as needed for tables in that database. If this value is specified without units, it is taken as seconds. The default is one minute (1min). This parameter can only be set in the postgresql.conf file or on the server command line.\n  autoanalyze_base_threshold (integer)\nSpecifies the minimum number of inserted, updated or deleted tuples needed to trigger an ANALYZE in any one table. The default is 50 tuples. This parameter can only be set in the postgresql.conf file or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.\n  autoanalyze_scale_factor (floating point)\nSpecifies a fraction of the table size to add to autoanalyze_base_threshold when deciding whether to trigger an ANALYZE. The default is 0.1 (10% of table size). This parameter can only be set in the postgresql.conf file or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.\n  Run-time Statistics     These parameters control server-wide statistics collection features. When statistics collection is enabled, the data that is produced can be accessed via the pg_stat and pg_statio family of system views. Refer to Chapter 27 for more information.\n  track_wait_events (boolean)\nEnables the collection of information on the wait events occured in each session, include occured times and timing information. This parameter is on by default. Note that even when enabled, this information is not visible to all users, only to superusers and the user owning the session being reported on, so it should not represent a security risk. Only superusers can change this setting.\n "},{"id":8,"href":"/installation/debian/","title":"Installing on Debian","parent":"Installation","content":"   Install Packages  Prerequisite Install Redrock Postgres   Control service After installation      Install Packages     Prerequisite     Log in to the host with your root account, and run the following commands to install dependent packages:\n# apt install postgresql-common postgresql-client-common Install Redrock Postgres     Download the Redrock Postgres Package for Debian, and run the following commands to install:\n# tar xf redrock-12.1-1.debian10.x86_64-bundle.tar # cd redrock-12.1-1.debian10.x86_64-bundle # dpkg -i libpq5_12.1-1_amd64.deb redrock-client_12.1-1_amd64.deb redrock_12.1-1_amd64.deb Other packages can be installed according to your needs.\nControl service     To control the database service, use:\n# systemctl \u0026lt;command\u0026gt; postgresql where command can be:\n enable : enable automatical start start : start the database stop : stop the database restart : stop/start the database; used to read changes to core configuration files reload : reload configuration files while keeping database running  After installation     Modify the pg_hba.conf file in configuration directory (default: /etc/postgresql/12/main/) to define what authentication method should be used from all networks to the PostgreSQL server and modify the localhost authentication method (change from indent to md5 and change from localhost to accept all incoming requests). Find the lines below:\n# IPv4 local connections: host all all 127.0.0.1/32 ident And change it to:\n# IPv4 local connections: host all all 0.0.0.0/0 md5 Modify the postgresql.conf file in configuration directory (default: /etc/postgresql/12/main/ ) to allow connections from all hosts by uncommenting the following line and adding an * instead of localhost:\nlisten_addresses = \u0026#39;*\u0026#39; Restart the database service to reload configurations:\n# systemctl restart postgresql In a production environment, you should also set up TLS-secured communication, and you should consider setting up data replication or snapshot-based backups. Consult the PostgreSQL online manual for these settings.\n"},{"id":9,"href":"/advanced/textsearch/","title":"Chinese Text Search","parent":"Advanced","content":"Full Text Searching (or just text search) provides the capability to identify natural-language documents that satisfy a query, and optionally to sort them by relevance to the query. The most common type of search is to find all documents containing given query terms and return them in order of their similarity to the query. Notions of query and similarity are very flexible and depend on the specific application. The simplest search considers query as a set of words and similarity as the frequency of query words in the document.\nParsers     Text search parsers are responsible for splitting raw document text into tokens and identifying each token\u0026rsquo;s type, where the set of possible types is defined by the parser itself. Note that a parser does not modify the text at all — it simply identifies plausible word boundaries. Because of this limited scope, there is less need for application-specific custom parsers than there is for custom dictionaries. At present Redrock Postgres provides just two built-in parser, which has been found to be useful for a wide range of applications.\nThe built-in chinese text parser is named pg_catalog.cjkparser.\nConfigurations     Full text search functionality includes the ability to do many more things: skip indexing certain words (stop words), process synonyms, and use sophisticated parsing, e.g., parse based on more than just white space. This functionality is controlled by text search configurations. PostgreSQL comes with predefined configurations for many languages, and you can easily create your own configurations. (psql\u0026rsquo;s \\dF command shows all available configurations.)\nThe built-in chinese text search configuration is named pg_catalog.chinese.\nTesting and Debugging Text Search     The behavior of a custom text search configuration can easily become confusing. The functions described in this section are useful for testing text search objects. You can test a complete configuration, or test parsers and dictionaries separately.\nConfiguration Testing     The function ts_debug allows easy testing of a text search configuration.\nSELECT * FROM ts_debug(\u0026#39;chinese\u0026#39;, \u0026#39;关系数据库是一种用于存储相互关联的数据记录并提供数据访问的数据库。\u0026#39;);\ralias | description | token | dictionaries | dictionary | lexemes\r------------+--------------+--------+--------------+------------+----------\rcjk_words | CJK words | 关系 | {chinese} | chinese | {关系}\rcjk_words | CJK words | 数据库 | {chinese} | chinese | {数据库}\rcjk_words | CJK words | 是 | {chinese} | chinese | {是}\rcjk_words | CJK words | 一种 | {chinese} | chinese | {一种}\rcjk_words | CJK words | 用于 | {chinese} | chinese | {用于}\rcjk_words | CJK words | 存储 | {chinese} | chinese | {存储}\rcjk_words | CJK words | 相互 | {chinese} | chinese | {相互}\rcjk_words | CJK words | 关联 | {chinese} | chinese | {关联}\rcjk_words | CJK words | 的 | {chinese} | chinese | {的}\rcjk_words | CJK words | 数据 | {chinese} | chinese | {数据}\rcjk_words | CJK words | 记录 | {chinese} | chinese | {记录}\rcjk_words | CJK words | 并 | {chinese} | chinese | {并}\rcjk_words | CJK words | 提供 | {chinese} | chinese | {提供}\rcjk_words | CJK words | 数据 | {chinese} | chinese | {数据}\rcjk_words | CJK words | 访问 | {chinese} | chinese | {访问}\rcjk_words | CJK words | 的 | {chinese} | chinese | {的}\rcjk_words | CJK words | 数据库 | {chinese} | chinese | {数据库}\rpunc_words | punctuations | 。 | {chinese} | chinese | {。} Parser Testing     The function ts_parse allows direct testing of a text search parser.\nSELECT * FROM ts_parse(\u0026#39;cjkparser\u0026#39;, \u0026#39;关系数据库是一种用于存储相互关联的数据记录并提供数据访问的数据库。\u0026#39;);\rtokid | token\r-------+--------\r1 | 关系\r1 | 数据库\r1 | 是\r1 | 一种\r1 | 用于\r1 | 存储\r1 | 相互\r1 | 关联\r1 | 的\r1 | 数据\r1 | 记录\r1 | 并\r1 | 提供\r1 | 数据\r1 | 访问\r1 | 的\r1 | 数据库\r18 | 。 "},{"id":10,"href":"/advanced/plscheme/","title":"PL/Scheme","parent":"Advanced","content":"PL/scheme is a PostgreSQL procedural language handler for Scheme programming language. PL/scheme uses Chibi Scheme in the background as its Scheme interpreter. With lots of builtin SRFIs and complete R7RS compliancy of Chibi Scheme, PL/scheme can power up PostgreSQL procedures in a Lisp style.\nFeatures     You can find some of the supported features by PL/scheme in the below list.\n Extensible native type support even for not created yet SQL data types. Domain, complex (ie. table\u0026rsquo;s row) and pseudo (record) types are supported as well. IN, INOUT and OUT argument mode functionality, Caching for non-volatile (and non-SRF) procedures per [top] transaction, and any available feature supported by Chibi Scheme (fully R7RS compliancy, module system extension, full access to POSIX system calls, networking support, multiple threads, powerful string processing, lots of builtin SRFIs and may others) are naturally shipped with PL/scheme too.  "},{"id":11,"href":"/features/undo/","title":"Undo","parent":"Features","content":"Redrock Postgres maintains records of the actions of transactions, collectively known as undo data. Redrock Postgres uses undo to do the following:\n Roll back an active transaction Recover a terminated transaction Provide read consistency  Redrock Postgres stores undo data inside the database rather than in external logs. Undo data is stored in blocks that are updated just like data blocks, with changes to these blocks generating redo. In this way, Redrock Postgres can efficiently access undo data without needing to read external logs.\nUndo data is stored in an independent tablespace. Redrock Postgres provides a fully automated mechanism, known as automatic undo management mode, for managing undos and space.\nUndos and Transactions     When a transaction starts, the database binds (assigns) the transaction to an undo segment, and therefore to a transaction table.\nMultiple active transactions can write concurrently to the same undo or to different undos. For example, transactions T1 and T2 can both write to undo U1, or T1 can write to U1 while T2 writes to undo U2.\nTransaction Rollback     When a ROLLBACK statement is issued, the database uses undo records to roll back changes made to the database by the uncommitted transaction. During recovery, the database rolls back any uncommitted changes applied from the online redo log to the data files. Undo records provide read consistency by maintaining the before image of the data for users accessing data at the same time that another user is changing it.\n"},{"id":12,"href":"/advanced/monitor-stats/","title":"Statistics Collector","parent":"Advanced","content":"PostgreSQL\u0026rsquo;s statistics collector is a subsystem that supports collection and reporting of information about server activity. Presently, the collector can count accesses to tables and indexes in both disk-block and individual-row terms. It also tracks the total number of rows in each table, and information about vacuum and analyze actions for each table. It can also count calls to user-defined functions and the total time spent in each one.\nPostgreSQL also supports reporting dynamic information about exactly what is going on in the system right now, such as the exact command currently being executed by other server processes, and which other connections exist in the system. This facility is independent of the collector process.\nStatistics Collection Configuration     Since collection of statistics adds some overhead to query execution, the system can be configured to collect or not collect information. This is controlled by configuration parameters that are normally set in postgresql.conf. (See Chapter 19 for details about setting configuration parameters.)\nThe parameter track_activities enables monitoring of the current command being executed by any server process.\nThe parameter track_counts controls whether statistics are collected about table and index accesses.\nThe parameter track_functions enables tracking of usage of user-defined functions.\nThe parameter track_io_timing enables monitoring of block read and write times.\nNormally these parameters are set in postgresql.conf so that they apply to all server processes, but it is possible to turn them on or off in individual sessions using the SET command. (To prevent ordinary users from hiding their activity from the administrator, only superusers are allowed to change these parameters with SET.)\nThe statistics collector transmits the collected information to other PostgreSQL processes through temporary files. These files are stored in the directory named by the stats_temp_directory parameter, pg_stat_tmp by default. For better performance, stats_temp_directory can be pointed at a RAM-based file system, decreasing physical I/O requirements. When the server shuts down cleanly, a permanent copy of the statistics data is stored in the pg_stat subdirectory, so that statistics can be retained across server restarts. When recovery is performed at server start (e.g., after immediate shutdown, server crash, and point-in-time recovery), all statistics counters are reset.\nViewing Statistics     Since collection of statistics adds some overhead to query execution, the system can be configured to collect or not collect information. This is controlled by configuration parameters that are normally set in postgresql.conf. (See Chapter 19 for details about setting configuration parameters.)\nSeveral predefined views, listed in Table 27.1, are available to show the current state of the system. There are also several other views, listed in Table 27.2, available to show the results of statistics collection. Alternatively, one can build custom views using the underlying statistics functions, as discussed in Section 27.2.3.\nWhen using the statistics to monitor collected data, it is important to realize that the information does not update instantaneously. Each individual server process transmits new statistical counts to the collector just before going idle; so a query or transaction still in progress does not affect the displayed totals. Also, the collector itself emits a new report at most once per PGSTAT_STAT_INTERVAL milliseconds (500 ms unless altered while building the server). So the displayed information lags behind actual activity. However, current-query information collected by track_activities is always up-to-date.\nAnother important point is that when a server process is asked to display any of these statistics, it first fetches the most recent report emitted by the collector process and then continues to use this snapshot for all statistical views and functions until the end of its current transaction. So the statistics will show static information as long as you continue the current transaction. Similarly, information about the current queries of all sessions is collected when any such information is first requested within a transaction, and the same information will be displayed throughout the transaction. This is a feature, not a bug, because it allows you to perform several queries on the statistics and correlate the results without worrying that the numbers are changing underneath you. But if you want to see new results with each query, be sure to do the queries outside any transaction block. Alternatively, you can invoke pg_stat_clear_snapshot(), which will discard the current transaction\u0026rsquo;s statistics snapshot (if any). The next use of statistical information will cause a new snapshot to be fetched.\nA transaction can also see its own statistics (as yet untransmitted to the collector) in the views pg_stat_xact_all_tables, pg_stat_xact_sys_tables, pg_stat_xact_user_tables, and pg_stat_xact_user_functions. These numbers do not act as stated above; instead they update continuously throughout the transaction.\nSome of the information in the dynamic statistics views shown in Table 27.1 is security restricted. Ordinary users can only see all the information about their own sessions (sessions belonging to a role that they are a member of). In rows about other sessions, many columns will be null. Note, however, that the existence of a session and its general properties such as its sessions user and database are visible to all users. Superusers and members of the built-in role pg_read_all_stats (see also Section 21.5) can see all the information about all sessions.\nTable 27.1. Dynamic Statistics Views\n   View Name Description     pg_stat_activity One row per server process, showing information related to the current activity of that process, such as state and current query. See pg_stat_activity for details.   pg_stat_wait_event One row per wait event, showing statistics about wait information of every occured wait events. See pg_stat_wait_event for details.   pg_stat_replication One row per WAL sender process, showing statistics about replication to that sender\u0026rsquo;s connected standby server. See pg_stat_replication for details.    Table 27.2. Collected Statistics Views\n   View Name Description     pg_stat_database One row per database, showing database-wide statistics. See pg_stat_database for details.   pg_stat_all_tables One row for each table in the current database, showing statistics about accesses to that specific table. See pg_stat_all_tables for details.   pg_stat_sys_tables Same as pg_stat_all_tables, except that only system tables are shown.   pg_stat_user_tables Same as pg_stat_all_tables, except that only user tables are shown.   pg_stat_xact_all_tables Similar to pg_stat_all_tables, but counts actions taken so far within the current transaction (which are not yet included in pg_stat_all_tables and related views). The columns for numbers of live and dead rows and vacuum and analyze actions are not present in this view.   pg_stat_xact_sys_tables Same as pg_stat_xact_all_tables, except that only system tables are shown.   pg_stat_xact_user_tables Same as pg_stat_xact_all_tables, except that only user tables are shown.   pg_stat_all_indexes One row for each index in the current database, showing statistics about accesses to that specific index. See pg_stat_all_indexes for details.   pg_stat_sys_indexes Same as pg_stat_all_indexes, except that only indexes on system tables are shown.   pg_stat_user_indexes Same as pg_stat_all_indexes, except that only indexes on user tables are shown.   pg_statio_all_tables One row for each table in the current database, showing statistics about I/O on that specific table. See pg_statio_all_tables for details.   pg_statio_sys_tables Same as pg_statio_all_tables, except that only system tables are shown.   pg_statio_user_tables Same as pg_statio_all_tables, except that only user tables are shown.   pg_statio_all_indexes One row for each index in the current database, showing statistics about I/O on that specific index. See pg_statio_all_indexes for details.   pg_statio_sys_indexes Same as pg_statio_all_indexes, except that only indexes on system tables are shown.   pg_statio_user_indexes Same as pg_statio_all_indexes, except that only indexes on user tables are shown.   pg_statio_all_sequences One row for each sequence in the current database, showing statistics about I/O on that specific sequence. See pg_statio_all_sequences for details.   pg_statio_sys_sequences Same as pg_statio_all_sequences, except that only system sequences are shown. (Presently, no system sequences are defined, so this view is always empty.)   pg_statio_user_sequences Same as pg_statio_all_sequences, except that only user sequences are shown.    The per-index statistics are particularly useful to determine which indexes are being used and how effective they are.\nThe pg_statio_ views are primarily useful to determine the effectiveness of the buffer cache. When the number of actual disk reads is much smaller than the number of buffer hits, then the cache is satisfying most read requests without invoking a kernel call. However, these statistics do not give the entire story: due to the way in which PostgreSQL handles disk I/O, data that is not in the PostgreSQL buffer cache might still reside in the kernel\u0026rsquo;s I/O cache, and might therefore still be fetched without requiring a physical read. Users interested in obtaining more detailed information on PostgreSQL I/O behavior are advised to use the PostgreSQL statistics collector in combination with operating system utilities that allow insight into the kernel\u0026rsquo;s handling of I/O.\nTable 27.3. pg_stat_activity View\n   Column Type Description     datid oid OID of the database this backend is connected to   datname name Name of the database this backend is connected to   pid integer Database Process ID of this backend   spid integer System Process ID of this backend   tid integer Thread ID of this backend   usesysid oid OID of the user logged into this backend   usename name Name of the user logged into this backend   application_name text Name of the application that is connected to this backend   client_addr inet IP address of the client connected to this backend. If this field is null, it indicates either that the client is connected via a Unix socket on the server machine or that this is an internal process such as autovacuum.   client_hostname text Host name of the connected client, as reported by a reverse DNS lookup of client_addr. This field will only be non-null for IP connections, and only when log_hostname is enabled.   client_port integer TCP port number that the client is using for communication with this backend, or -1 if a Unix socket is used   backend_start timestamp with time zone Time when this process was started. For client backends, this is the time the client connected to the server.   xact_start timestamp with time zone Time when this process\u0026rsquo; current transaction was started, or null if no transaction is active. If the current query is the first of its transaction, this column is equal to the query_start column.   query_start timestamp with time zone Time when the currently active query was started, or if state is not active, when the last query was started   state_change timestamp with time zone Time when the state was last changed   wait_event_type text The type of event for which the backend is waiting, if any; otherwise NULL. Possible values are:LWLock: The backend is waiting for a lightweight lock. Each such lock protects a particular data structure in shared memory. wait_event will contain a name identifying the purpose of the lightweight lock. (Some locks have specific names; others are part of a group of locks each with a similar purpose.)Lock: The backend is waiting for a heavyweight lock. Heavyweight locks, also known as lock manager locks or simply locks, primarily protect SQL-visible objects such as tables. However, they are also used to ensure mutual exclusion for certain internal operations such as relation extension. wait_event will identify the type of lock awaited.BufferPin: The server process is waiting to access to a data buffer during a period when no other process can be examining that buffer. Buffer pin waits can be protracted if another process holds an open cursor which last read data from the buffer in question.Activity: The server process is idle. This is used by system processes waiting for activity in their main processing loop. wait_event will identify the specific wait point.Extension: The server process is waiting for activity in an extension module. This category is useful for modules to track custom waiting points.Client: The server process is waiting for some activity on a socket from user applications, and that the server expects something to happen that is independent from its internal processes. wait_event will identify the specific wait point.IPC: The server process is waiting for some activity from another process in the server. wait_event will identify the specific wait point.Timeout: The server process is waiting for a timeout to expire. wait_event will identify the specific wait point.IO: The server process is waiting for a IO to complete. wait_event will identify the specific wait point.   wait_event text Wait event name if backend is currently waiting, otherwise NULL. See Table 27.4 for details.   memory_used bigint Memory used by this backend.   state text Current overall state of this backend. Possible values are:active: The backend is executing a query.idle: The backend is waiting for a new client command.idle in transaction: The backend is in a transaction, but is not currently executing a query.idle in transaction (aborted): This state is similar to idle in transaction, except one of the statements in the transaction caused an error.fastpath function call: The backend is executing a fast-path function.disabled: This state is reported if track_activities is disabled in this backend.   backend_xid xid Top-level transaction identifier of this backend, if any.   backend_mintime xid The current backend\u0026rsquo;s mintime horizon.   query text Text of this backend\u0026rsquo;s most recent query. If state is active this field shows the currently executing query. In all other states, it shows the last query that was executed. By default the query text is truncated at 1024 bytes; this value can be changed via the parameter track_activity_query_size.   backend_type text Type of current backend. Possible types are autoanalyze launcher, autoanalyze worker, logical replication launcher, logical replication worker, parallel worker, background writer, client backend, checkpointer, startup, walreceiver, walsender and walwriter. In addition, background workers registered by extensions may have additional types.    The pg_stat_activity view will have one row per server process, showing information related to the current activity of that process.\nNote     The wait_event and state columns are independent. If a backend is in the active state, it may or may not be waiting on some event. If the state is active and wait_event is non-null, it means that a query is being executed, but is being blocked somewhere in the system.\nTable 28.4. Wait Event Types\n   Wait Event Type Description     Activity The server process is idle. This event type indicates a process waiting for activity in its main processing loop. wait_event will identify the specific wait point; see Table 28.5.   BufferPin The server process is waiting for exclusive access to a data buffer. Buffer pin waits can be protracted if another process holds an open cursor that last read data from the buffer in question. See Table 28.6.   Client The server process is waiting for activity on a socket connected to a user application. Thus, the server expects something to happen that is independent of its internal processes. wait_event will identify the specific wait point; see Table 28.7.   Extension The server process is waiting for some condition defined by an extension module. See Table 28.8.   IO The server process is waiting for an I/O operation to complete. wait_event will identify the specific wait point; see Table 28.9.   IPC The server process is waiting for some interaction with another server process. wait_event will identify the specific wait point; see Table 28.10.   Lock The server process is waiting for a heavyweight lock. Heavyweight locks, also known as lock manager locks or simply locks, primarily protect SQL-visible objects such as tables. However, they are also used to ensure mutual exclusion for certain internal operations such as relation extension. wait_event will identify the type of lock awaited; see Table 28.11.   LWLock The server process is waiting for a lightweight lock. Most such locks protect a particular data structure in shared memory. wait_event will contain a name identifying the purpose of the lightweight lock. (Some locks have specific names; others are part of a group of locks each with a similar purpose.) See Table 28.12.   Timeout The server process is waiting for a timeout to expire. wait_event will identify the specific wait point; see Table 28.13.    Table 28.5. Wait Events of Type Activity\n   Activity Wait Event Description     ArchiverMain Waiting in main loop of archiver process.   AnalyzeLauncherMain Waiting in main loop of autoanalyze launcher process.   BgWriterHibernate Waiting in background writer process, hibernating.   BgWriterMain Waiting in main loop of background writer process.   CheckpointerMain Waiting in main loop of checkpointer process.   LogicalApplyMain Waiting in main loop of logical replication apply process.   LogicalLauncherMain Waiting in main loop of logical replication launcher process.   PgStatMain Waiting in main loop of statistics collector process.   RecoveryWalStream Waiting in main loop of startup process for WAL to arrive, during streaming recovery.   SysLoggerMain Waiting in main loop of syslogger process.   WalReceiverMain Waiting in main loop of WAL receiver process.   WalSenderMain Waiting in main loop of WAL sender process.   WalWriterMain Waiting in main loop of WAL writer process.    Table 28.6. Wait Events of Type BufferPin\n   BufferPin Wait Event Description     BufferPin Waiting to acquire an exclusive pin on a buffer.    Table 28.7. Wait Events of Type Client\n   Client Wait Event Description     ClientRead Waiting to read data from the client.   ClientWrite Waiting to write data to the client.   GSSOpenServer Waiting to read data from the client while establishing a GSSAPI session.   LibPQWalReceiverConnect Waiting in WAL receiver to establish connection to remote server.   LibPQWalReceiverReceive Waiting in WAL receiver to receive data from remote server.   SSLOpenServer Waiting for SSL while attempting connection.   WalSenderWaitForWAL Waiting for WAL to be flushed in WAL sender process.   WalSenderWriteData Waiting for any activity when processing replies from WAL receiver in WAL sender process.    Table 28.8. Wait Events of Type Extension\n   Extension Wait Event Description     Extension Waiting in an extension.    Table 28.9. Wait Events of Type IO\n   IO Wait Event Description     BaseBackupRead Waiting for base backup to read from a file.   BufFileRead Waiting for a read from a buffered file.   BufFileWrite Waiting for a write to a buffered file.   BufFileTruncate Waiting for a buffered file to be truncated.   ControlFileRead Waiting for a read from the pg_control file.   ControlFileSync Waiting for the pg_control file to reach durable storage.   ControlFileSyncUpdate Waiting for an update to the pg_control file to reach durable storage.   ControlFileWrite Waiting for a write to the pg_control file.   ControlFileWriteUpdate Waiting for a write to update the pg_control file.   CopyFileRead Waiting for a read during a file copy operation.   CopyFileWrite Waiting for a write during a file copy operation.   DSMFillZeroWrite Waiting to fill a dynamic shared memory backing file with zeroes.   DataFileExtend Waiting for a relation data file to be extended.   DataFileFlush Waiting for a relation data file to reach durable storage.   DataFileImmediateSync Waiting for an immediate synchronization of a relation data file to durable storage.   DataFilePrefetch Waiting for an asynchronous prefetch from a relation data file.   DataFileRead Waiting for a read from a relation data file.   DataFileSync Waiting for changes to a relation data file to reach durable storage.   DataFileTruncate Waiting for a relation data file to be truncated.   DataFileWrite Waiting for a write to a relation data file.   LockFileAddToDataDirRead Waiting for a read while adding a line to the data directory lock file.   LockFileAddToDataDirSync Waiting for data to reach durable storage while adding a line to the data directory lock file.   LockFileAddToDataDirWrite Waiting for a write while adding a line to the data directory lock file.   LockFileCreateRead Waiting to read while creating the data directory lock file.   LockFileCreateSync Waiting for data to reach durable storage while creating the data directory lock file.   LockFileCreateWrite Waiting for a write while creating the data directory lock file.   LockFileReCheckDataDirRead Waiting for a read during recheck of the data directory lock file.   LogicalRewriteCheckpointSync Waiting for logical rewrite mappings to reach durable storage during a checkpoint.   LogicalRewriteMappingSync Waiting for mapping data to reach durable storage during a logical rewrite.   LogicalRewriteMappingWrite Waiting for a write of mapping data during a logical rewrite.   LogicalRewriteSync Waiting for logical rewrite mappings to reach durable storage.   LogicalRewriteTruncate Waiting for truncate of mapping data during a logical rewrite.   LogicalRewriteWrite Waiting for a write of logical rewrite mappings.   RelationMapRead Waiting for a read of the relation map file.   RelationMapSync Waiting for the relation map file to reach durable storage.   RelationMapWrite Waiting for a write to the relation map file.   ReorderBufferRead Waiting for a read during reorder buffer management.   ReorderBufferWrite Waiting for a write during reorder buffer management.   ReorderLogicalMappingRead Waiting for a read of a logical mapping during reorder buffer management.   ReplicationSlotRead Waiting for a read from a replication slot control file.   ReplicationSlotRestoreSync Waiting for a replication slot control file to reach durable storage while restoring it to memory.   ReplicationSlotSync Waiting for a replication slot control file to reach durable storage.   ReplicationSlotWrite Waiting for a write to a replication slot control file.   SLRUFlushSync Waiting for SLRU data to reach durable storage during a checkpoint or database shutdown.   SLRURead Waiting for a read of an SLRU page.   SLRUSync Waiting for SLRU data to reach durable storage following a page write.   SLRUWrite Waiting for a write of an SLRU page.   SnapbuildRead Waiting for a read of a serialized historical catalog snapshot.   SnapbuildSync Waiting for a serialized historical catalog snapshot to reach durable storage.   SnapbuildWrite Waiting for a write of a serialized historical catalog snapshot.   TimelineHistoryFileSync Waiting for a timeline history file received via streaming replication to reach durable storage.   TimelineHistoryFileWrite Waiting for a write of a timeline history file received via streaming replication.   TimelineHistoryRead Waiting for a read of a timeline history file.   TimelineHistorySync Waiting for a newly created timeline history file to reach durable storage.   TimelineHistoryWrite Waiting for a write of a newly created timeline history file.   TwophaseFileRead Waiting for a read of a two phase state file.   TwophaseFileSync Waiting for a two phase state file to reach durable storage.   TwophaseFileWrite Waiting for a write of a two phase state file.   WALBootstrapSync Waiting for WAL to reach durable storage during bootstrapping.   WALBootstrapWrite Waiting for a write of a WAL page during bootstrapping.   WALCopyRead Waiting for a read when creating a new WAL segment by copying an existing one.   WALCopySync Waiting for a new WAL segment created by copying an existing one to reach durable storage.   WALCopyWrite Waiting for a write when creating a new WAL segment by copying an existing one.   WALInitSync Waiting for a newly initialized WAL file to reach durable storage.   WALInitWrite Waiting for a write while initializing a new WAL file.   WALRead Waiting for a read from a WAL file.   WALSenderTimelineHistoryRead Waiting for a read from a timeline history file during a walsender timeline command.   WALSync Waiting for a WAL file to reach durable storage.   WALSyncMethodAssign Waiting for data to reach durable storage while assigning a new WAL sync method.   WALWrite Waiting for a write to a WAL file.   LogicalChangesRead Waiting for a read from a logical changes file.   LogicalChangesWrite Waiting for a write to a logical changes file.   LogicalSubxactRead Waiting for a read from a logical subxact file.   LogicalSubxactWrite Waiting for a write to a logical subxact file.    Table 28.10. Wait Events of Type IPC\n   IPC Wait Event Description     AppendReady Waiting for subplan nodes of an Append plan node to be ready.   BackendTermination Waiting for the termination of another backend.   BackupWaitWalArchive Waiting for WAL files required for a backup to be successfully archived.   BgWorkerShutdown Waiting for background worker to shut down.   BgWorkerStartup Waiting for background worker to start up.   BtreePage Waiting for the page number needed to continue a parallel B-tree scan to become available.   BufferIO Waiting for buffer I/O to complete.   CheckpointDone Waiting for a checkpoint to complete.   CheckpointStart Waiting for a checkpoint to start.   ExecuteGather Waiting for activity from a child process while executing a Gather plan node.   HashBatchAllocate Waiting for an elected Parallel Hash participant to allocate a hash table.   HashBatchElect Waiting to elect a Parallel Hash participant to allocate a hash table.   HashBatchLoad Waiting for other Parallel Hash participants to finish loading a hash table.   HashBuildAllocate Waiting for an elected Parallel Hash participant to allocate the initial hash table.   HashBuildElect Waiting to elect a Parallel Hash participant to allocate the initial hash table.   HashBuildHashInner Waiting for other Parallel Hash participants to finish hashing the inner relation.   HashBuildHashOuter Waiting for other Parallel Hash participants to finish partitioning the outer relation.   HashGrowBatchesAllocate Waiting for an elected Parallel Hash participant to allocate more batches.   HashGrowBatchesDecide Waiting to elect a Parallel Hash participant to decide on future batch growth.   HashGrowBatchesElect Waiting to elect a Parallel Hash participant to allocate more batches.   HashGrowBatchesFinish Waiting for an elected Parallel Hash participant to decide on future batch growth.   HashGrowBatchesRepartition Waiting for other Parallel Hash participants to finish repartitioning.   HashGrowBucketsAllocate Waiting for an elected Parallel Hash participant to finish allocating more buckets.   HashGrowBucketsElect Waiting to elect a Parallel Hash participant to allocate more buckets.   HashGrowBucketsReinsert Waiting for other Parallel Hash participants to finish inserting tuples into new buckets.   LogicalSyncData Waiting for a logical replication remote server to send data for initial table synchronization.   LogicalSyncStateChange Waiting for a logical replication remote server to change state.   MessageQueueInternal Waiting for another process to be attached to a shared message queue.   MessageQueuePutMessage Waiting to write a protocol message to a shared message queue.   MessageQueueReceive Waiting to receive bytes from a shared message queue.   MessageQueueSend Waiting to send bytes to a shared message queue.   ParallelBitmapScan Waiting for parallel bitmap scan to become initialized.   ParallelCreateIndexScan Waiting for parallel CREATE INDEX workers to finish heap scan.   ParallelFinish Waiting for parallel workers to finish computing.   ProcArrayGroupUpdate Waiting for the group leader to clear the transaction ID at end of a parallel operation.   ProcSignalBarrier Waiting for a barrier event to be processed by all backends.   Promote Waiting for standby promotion.   RecoveryConflictSnapshot Waiting for recovery conflict resolution for a vacuum cleanup.   RecoveryConflictTablespace Waiting for recovery conflict resolution for dropping a tablespace.   RecoveryPause Waiting for recovery to be resumed.   ReplicationOriginDrop Waiting for a replication origin to become inactive so it can be dropped.   ReplicationSlotDrop Waiting for a replication slot to become inactive so it can be dropped.   SafeSnapshot Waiting to obtain a valid snapshot for a READ ONLY DEFERRABLE transaction.   SyncRep Waiting for confirmation from a remote server during synchronous replication.   WalReceiverExit Waiting for the WAL receiver to exit.   WalReceiverWaitStart Waiting for startup process to send initial data for streaming replication.   XactGroupUpdate Waiting for the group leader to update transaction status at end of a parallel operation.    Table 28.11. Wait Events of Type Lock\n   Lock Wait Event Description     advisory Waiting to acquire an advisory user lock.   extend Waiting to extend a relation.   frozenid Waiting to update pg_database.datfrozenxid and pg_database.datminmxid.   object Waiting to acquire a lock on a non-relation database object.   page Waiting to acquire a lock on a page of a relation.   relation Waiting to acquire a lock on a relation.   spectoken Waiting to acquire a speculative insertion lock.   transactionid Waiting for a transaction to finish.   tuple Waiting to acquire a lock on a tuple.   userlock Waiting to acquire a user lock.   virtualxid Waiting to acquire a virtual transaction ID lock.    Table 28.12. Wait Events of Type LWLock\n   LWLock Wait Event Description     AddinShmemInit Waiting to manage an extension\u0026rsquo;s space allocation in shared memory.   AutoFile Waiting to update the postgresql.auto.conf file.   Autovacuum Waiting to read or update the current state of autovacuum workers.   AutovacuumSchedule Waiting to ensure that a table selected for autovacuum still needs vacuuming.   BackgroundWorker Waiting to read or update background worker state.   BtreeVacuum Waiting to read or update vacuum-related information for a B-tree index.   BufferContent Waiting to access a data page in memory.   BufferMapping Waiting to associate a data block with a buffer in the buffer pool.   CheckpointerComm Waiting to manage fsync requests.   CommitTs Waiting to read or update the last value set for a transaction commit timestamp.   CommitTsBuffer Waiting for I/O on a commit timestamp SLRU buffer.   CommitTsSLRU Waiting to access the commit timestamp SLRU cache.   ControlFile Waiting to read or update the pg_control file or create a new WAL file.   DynamicSharedMemoryControl Waiting to read or update dynamic shared memory allocation information.   LockFastPath Waiting to read or update a process\u0026rsquo; fast-path lock information.   LockManager Waiting to read or update information about “heavyweight” locks.   LogicalRepWorker Waiting to read or update the state of logical replication workers.   MultiXactGen Waiting to read or update shared multixact state.   MultiXactMemberBuffer Waiting for I/O on a multixact member SLRU buffer.   MultiXactMemberSLRU Waiting to access the multixact member SLRU cache.   MultiXactOffsetBuffer Waiting for I/O on a multixact offset SLRU buffer.   MultiXactOffsetSLRU Waiting to access the multixact offset SLRU cache.   MultiXactTruncation Waiting to read or truncate multixact information.   NotifyBuffer Waiting for I/O on a NOTIFY message SLRU buffer.   NotifyQueue Waiting to read or update NOTIFY messages.   NotifyQueueTail Waiting to update limit on NOTIFY message storage.   NotifySLRU Waiting to access the NOTIFY message SLRU cache.   OidGen Waiting to allocate a new OID.   OldSnapshotTimeMap Waiting to read or update old snapshot control information.   ParallelAppend Waiting to choose the next subplan during Parallel Append plan execution.   ParallelHashJoin Waiting to synchronize workers during Parallel Hash Join plan execution.   ParallelQueryDSA Waiting for parallel query dynamic shared memory allocation.   PerSessionDSA Waiting for parallel query dynamic shared memory allocation.   PerSessionRecordType Waiting to access a parallel query\u0026rsquo;s information about composite types.   PerSessionRecordTypmod Waiting to access a parallel query\u0026rsquo;s information about type modifiers that identify anonymous record types.   PerXactPredicateList Waiting to access the list of predicate locks held by the current serializable transaction during a parallel query.   PredicateLockManager Waiting to access predicate lock information used by serializable transactions.   ProcArray Waiting to access the shared per-process data structures (typically, to get a snapshot or report a session\u0026rsquo;s transaction ID).   RelationMapping Waiting to read or update a pg_filenode.map file (used to track the filenode assignments of certain system catalogs).   RelCacheInit Waiting to read or update a pg_internal.init relation cache initialization file.   ReplicationOrigin Waiting to create, drop or use a replication origin.   ReplicationOriginState Waiting to read or update the progress of one replication origin.   ReplicationSlotAllocation Waiting to allocate or free a replication slot.   ReplicationSlotControl Waiting to read or update replication slot state.   ReplicationSlotIO Waiting for I/O on a replication slot.   SerialBuffer Waiting for I/O on a serializable transaction conflict SLRU buffer.   SerializableFinishedList Waiting to access the list of finished serializable transactions.   SerializablePredicateList Waiting to access the list of predicate locks held by serializable transactions.   SerializableXactHash Waiting to read or update information about serializable transactions.   SerialSLRU Waiting to access the serializable transaction conflict SLRU cache.   SharedTidBitmap Waiting to access a shared TID bitmap during a parallel bitmap index scan.   SharedTupleStore Waiting to access a shared tuple store during parallel query.   ShmemIndex Waiting to find or allocate space in shared memory.   SInvalRead Waiting to retrieve messages from the shared catalog invalidation queue.   SInvalWrite Waiting to add a message to the shared catalog invalidation queue.   SubtransBuffer Waiting for I/O on a sub-transaction SLRU buffer.   SubtransSLRU Waiting to access the sub-transaction SLRU cache.   SyncRep Waiting to read or update information about the state of synchronous replication.   SyncScan Waiting to select the starting location of a synchronized table scan.   TablespaceCreate Waiting to create or drop a tablespace.   TwoPhaseState Waiting to read or update the state of prepared transactions.   WALBufMapping Waiting to replace a page in WAL buffers.   WALInsert Waiting to insert WAL data into a memory buffer.   WALWrite Waiting for WAL buffers to be written to disk.   WrapLimitsVacuum Waiting to update limits on transaction id and multixact consumption.   XactBuffer Waiting for I/O on a transaction status SLRU buffer.   XactSLRU Waiting to access the transaction status SLRU cache.   XactTruncation Waiting to execute pg_xact_status or update the oldest transaction ID available to it.   XidGen Waiting to allocate a new transaction ID.    Note     Extensions can add LWLock types to the list shown in Table 28.12. In some cases, the name assigned by an extension will not be available in all server processes; so an LWLock wait event might be reported as just “extension” rather than the extension-assigned name.\nTable 28.13. Wait Events of Type Timeout\n   Timeout Wait Event Description     BaseBackupThrottle Waiting during base backup when throttling activity.   CheckpointWriteDelay Waiting between writes while performing a checkpoint.   PgSleep Waiting due to a call to pg_sleep or a sibling function.   RecoveryApplyDelay Waiting to apply WAL during recovery because of a delay setting.   RecoveryRetrieveRetryInterval Waiting during recovery when WAL data is not available from any source (pg_wal, archive or stream).   RegisterSyncRequest Waiting while sending synchronization requests to the checkpointer, because the request queue is full.   VacuumDelay Waiting in a cost-based vacuum delay point.    Here is an example of how wait events can be viewed:\nSELECT pid, wait_event_type, wait_event FROM pg_stat_activity WHERE wait_event is NOT NULL;\rpid | wait_event_type | wait_event ------+-----------------+------------\r2540 | Lock | relation\r6644 | LWLock | ProcArray\r(2 rows) Table 27.15. pg_stat_wait_event View\n   Column Type Description     wait_event_type text The type of event for which the backend is waiting, if any; otherwise NULL.   wait_event text Wait event name if backend is currently waiting, otherwise NULL. See Table 27.4 for details.   waits bigint Number of times this event has occured   total_time double precision Total time spent in the event, in milliseconds   min_time double precision Minimum time spent in the event, in milliseconds   max_time double precision Maximum time spent in the event, in milliseconds   mean_time double precision Mean time spent in the event, in milliseconds    The pg_stat_wait_event view will contain one row for each wait event in the current database, showing statistics about wait information of every occured wait events.\nTable 27.5. pg_stat_replication View\n   Column Type Description     pid integer Process ID of a WAL sender process   usesysid oid OID of the user logged into this WAL sender process   usename name Name of the user logged into this WAL sender process   application_name text Name of the application that is connected to this WAL sender   client_addr inet IP address of the client connected to this WAL sender. If this field is null, it indicates that the client is connected via a Unix socket on the server machine.   client_hostname text Host name of the connected client, as reported by a reverse DNS lookup of client_addr. This field will only be non-null for IP connections, and only when log_hostname is enabled.   client_port integer TCP port number that the client is using for communication with this WAL sender, or -1 if a Unix socket is used   backend_start timestamp with time zone Time when this process was started, i.e., when the client connected to this WAL sender   backend_xmin xid This standby\u0026rsquo;s xmin horizon reported by hot_standby_feedback.   state text Current WAL sender state. Possible values are:startup: This WAL sender is starting up.catchup: This WAL sender\u0026rsquo;s connected standby is catching up with the primary.streaming: This WAL sender is streaming changes after its connected standby server has caught up with the primary.backup: This WAL sender is sending a backup.stopping: This WAL sender is stopping.   sent_lsn pg_lsn Last write-ahead log location sent on this connection   write_lsn pg_lsn Last write-ahead log location written to disk by this standby server   flush_lsn pg_lsn Last write-ahead log location flushed to disk by this standby server   replay_lsn pg_lsn Last write-ahead log location replayed into the database on this standby server   write_lag interval Time elapsed between flushing recent WAL locally and receiving notification that this standby server has written it (but not yet flushed it or applied it). This can be used to gauge the delay that synchronous_commit level remote_write incurred while committing if this server was configured as a synchronous standby.   flush_lag interval Time elapsed between flushing recent WAL locally and receiving notification that this standby server has written and flushed it (but not yet applied it). This can be used to gauge the delay that synchronous_commit level on incurred while committing if this server was configured as a synchronous standby.   replay_lag interval Time elapsed between flushing recent WAL locally and receiving notification that this standby server has written, flushed and applied it. This can be used to gauge the delay that synchronous_commit level remote_apply incurred while committing if this server was configured as a synchronous standby.   sync_priority integer Priority of this standby server for being chosen as the synchronous standby in a priority-based synchronous replication. This has no effect in a quorum-based synchronous replication.   sync_state text Synchronous state of this standby server. Possible values are:async: This standby server is asynchronous.potential: This standby server is now asynchronous, but can potentially become synchronous if one of current synchronous ones fails.sync: This standby server is synchronous.quorum: This standby server is considered as a candidate for quorum standbys.   reply_time timestamp with time zone Send time of last reply message received from standby server    The pg_stat_replication view will contain one row per WAL sender process, showing statistics about replication to that sender\u0026rsquo;s connected standby server. Only directly connected standbys are listed; no information is available about downstream standby servers.\nThe lag times reported in the pg_stat_replication view are measurements of the time taken for recent WAL to be written, flushed and replayed and for the sender to know about it. These times represent the commit delay that was (or would have been) introduced by each synchronous commit level, if the remote server was configured as a synchronous standby. For an asynchronous standby, the replay_lag column approximates the delay before recent transactions became visible to queries. If the standby server has entirely caught up with the sending server and there is no more WAL activity, the most recently measured lag times will continue to be displayed for a short time and then show NULL.\nLag times work automatically for physical replication. Logical decoding plugins may optionally emit tracking messages; if they do not, the tracking mechanism will simply display NULL lag.\nNote     The reported lag times are not predictions of how long it will take for the standby to catch up with the sending server assuming the current rate of replay. Such a system would show similar times while new WAL is being generated, but would differ when the sender becomes idle. In particular, when the standby has caught up completely, pg_stat_replication shows the time taken to write, flush and replay the most recent reported WAL location rather than zero as some users might expect. This is consistent with the goal of measuring synchronous commit and transaction visibility delays for recent write transactions. To reduce confusion for users expecting a different model of lag, the lag columns revert to NULL after a short time on a fully replayed idle system. Monitoring systems should choose whether to represent this as missing data, zero or continue to display the last known value.\nTable 27.12. pg_stat_database View\n   Column Type Description     datid oid OID of this database, or 0 for objects belonging to a shared relation   datname name Name of this database, or NULL for the shared objects.   numbackends integer Number of backends currently connected to this database, or NULL for the shared objects. This is the only column in this view that returns a value reflecting current state; all other columns return the accumulated values since the last reset.   xact_commit bigint Number of transactions in this database that have been committed   xact_rollback bigint Number of transactions in this database that have been rolled back   blks_read bigint Number of disk blocks read in this database   blks_hit bigint Number of times disk blocks were found already in the buffer cache, so that a read was not necessary (this only includes hits in the PostgreSQL buffer cache, not the operating system\u0026rsquo;s file system cache)   tup_returned bigint Number of rows returned by queries in this database   tup_fetched bigint Number of rows fetched by queries in this database   tup_inserted bigint Number of rows inserted by queries in this database   tup_updated bigint Number of rows updated by queries in this database   tup_deleted bigint Number of rows deleted by queries in this database   conflicts bigint Number of queries canceled due to conflicts with recovery in this database. (Conflicts occur only on standby servers; see pg_stat_database_conflicts for details.)   temp_files bigint Number of temporary files created by queries in this database. All temporary files are counted, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the log_temp_files setting.   temp_bytes bigint Total amount of data written to temporary files by queries in this database. All temporary files are counted, regardless of why the temporary file was created, and regardless of the log_temp_files setting.   deadlocks bigint Number of deadlocks detected in this database   checksum_failures bigint Number of data page checksum failures detected in this database (or on a shared object), or NULL if data checksums are not enabled.   checksum_last_failure timestamp with time zone Time at which the last data page checksum failure was detected in this database (or on a shared object), or NULL if data checksums are not enabled.   blk_read_time double precision Time spent reading data file blocks by backends in this database, in milliseconds   blk_write_time double precision Time spent writing data file blocks by backends in this database, in milliseconds   stats_reset timestamp with time zone Time at which these statistics were last reset    The pg_stat_database view will contain one row for each database in the cluster, plus one for the shared objects, showing database-wide statistics.\nTable 27.14. pg_stat_all_tables View\n   Column Type Description     relid oid OID of a table   schemaname name Name of the schema that this table is in   relname name Name of this table   seq_scan bigint Number of sequential scans initiated on this table   seq_tup_read bigint Number of live rows fetched by sequential scans   idx_scan bigint Number of index scans initiated on this table   idx_tup_fetch bigint Number of live rows fetched by index scans   n_tup_ins bigint Number of rows inserted   n_tup_upd bigint Number of rows updated (includes HOT updated rows)   n_tup_del bigint Number of rows deleted   n_tup_hot_upd bigint Number of rows HOT updated (i.e., with no separate index update required)   n_live_tup bigint Estimated number of live rows   n_dead_tup bigint Estimated number of dead rows   n_mod_since_analyze bigint Estimated number of rows modified since this table was last analyzed   last_vacuum timestamp with time zone Last time at which this table was manually vacuumed (not counting VACUUM FULL)   last_autovacuum timestamp with time zone Last time at which this table was vacuumed by the autovacuum daemon   last_analyze timestamp with time zone Last time at which this table was manually analyzed   last_autoanalyze timestamp with time zone Last time at which this table was analyzed by the autovacuum daemon   vacuum_count bigint Number of times this table has been manually vacuumed (not counting VACUUM FULL)   autovacuum_count bigint Number of times this table has been vacuumed by the autovacuum daemon   analyze_count bigint Number of times this table has been manually analyzed   autoanalyze_count bigint Number of times this table has been analyzed by the autovacuum daemon    The pg_stat_all_tables view will contain one row for each table in the current database (including TOAST tables), showing statistics about accesses to that specific table. The pg_stat_user_tables and pg_stat_sys_tables views contain the same information, but filtered to only show user and system tables respectively.\nTable 27.15. pg_stat_all_indexes View\n   Column Type Description     relid oid OID of the table for this index   indexrelid oid OID of this index   schemaname name Name of the schema this index is in   relname name Name of the table for this index   indexrelname name Name of this index   idx_scan bigint Number of index scans initiated on this index   idx_tup_read bigint Number of index entries returned by scans on this index   idx_tup_fetch bigint Number of live table rows fetched by simple index scans using this index    The pg_stat_all_indexes view will contain one row for each index in the current database, showing statistics about accesses to that specific index. The pg_stat_user_indexes and pg_stat_sys_indexes views contain the same information, but filtered to only show user and system indexes respectively.\nIndexes can be used by simple index scans, “bitmap” index scans, and the optimizer. In a bitmap scan the output of several indexes can be combined via AND or OR rules, so it is difficult to associate individual heap row fetches with specific indexes when a bitmap scan is used. Therefore, a bitmap scan increments the pg_stat_all_indexes.idx_tup_read count(s) for the index(es) it uses, and it increments the pg_stat_all_tables.idx_tup_fetch count for the table, but it does not affect pg_stat_all_indexes.idx_tup_fetch. The optimizer also accesses indexes to check for supplied constants whose values are outside the recorded range of the optimizer statistics because the optimizer statistics might be stale.\nNote     The idx_tup_read and idx_tup_fetch counts can be different even without any use of bitmap scans, because idx_tup_read counts index entries retrieved from the index while idx_tup_fetch counts live rows fetched from the table. The latter will be less if any dead or not-yet-committed rows are fetched using the index, or if any heap fetches are avoided by means of an index-only scan.\nTable 27.16. pg_statio_all_tables View\n   Column Type Description     relid oid OID of a table   schemaname name Name of the schema that this table is in   relname name Name of this table   heap_blks_read bigint Number of disk blocks read from this table   heap_blks_hit bigint Number of buffer hits in this table   idx_blks_read bigint Number of disk blocks read from all indexes on this table   idx_blks_hit bigint Number of buffer hits in all indexes on this table   toast_blks_read bigint Number of disk blocks read from this table\u0026rsquo;s TOAST table (if any)   toast_blks_hit bigint Number of buffer hits in this table\u0026rsquo;s TOAST table (if any)   tidx_blks_read bigint Number of disk blocks read from this table\u0026rsquo;s TOAST table indexes (if any)   tidx_blks_hit bigint Number of buffer hits in this table\u0026rsquo;s TOAST table indexes (if any)    The pg_statio_all_tables view will contain one row for each table in the current database (including TOAST tables), showing statistics about I/O on that specific table. The pg_statio_user_tables and pg_statio_sys_tables views contain the same information, but filtered to only show user and system tables respectively.\nTable 27.17. pg_statio_all_indexes View\n   Column Type Description     relid oid OID of the table for this index   indexrelid oid OID of this index   schemaname name Name of the schema this index is in   relname name Name of the table for this index   indexrelname name Name of this index   idx_blks_read bigint Number of disk blocks read from this index   idx_blks_hit bigint Number of buffer hits in this index    The pg_statio_all_indexes view will contain one row for each index in the current database, showing statistics about I/O on that specific index. The pg_statio_user_indexes and pg_statio_sys_indexes views contain the same information, but filtered to only show user and system indexes respectively.\nTable 27.18. pg_statio_all_sequences View\n   Column Type Description     relid oid OID of a sequence   schemaname name Name of the schema this sequence is in   relname name Name of this sequence   blks_read bigint Number of disk blocks read from this sequence   blks_hit bigint Number of buffer hits in this sequence    The pg_statio_all_sequences view will contain one row for each sequence in the current database, showing statistics about I/O on that specific sequence.\n"},{"id":13,"href":"/posts/","title":"News","parent":"Welcome to Redrock Documentation","content":""},{"id":14,"href":"/posts/initial-release/","title":"Redrock Postgres version 12.1-1 Released","parent":"News","content":"The Redrock Development Team is pleased to announce Redrock Postgres 12 version 12.1-1.\nRedrock is an object-relational database management system (ORDBMS) based on PostgreSQL, developed by the PostgreSQL Global Development Group. It is intentionally designed as an enterprise grade and cloud native database.\nFor more information, please see the website.\nFeature overview:\n Undo: Log record for roll back modified data and transactions. Multitenant: Single database instance runs on a server and serves multiple tenants. Network based tablespace: Devide computing and storage functions in database through network based tablespace. Multithread: The multithreaded database model enables server processes to execute as operating system threads in separate address spaces. Recyclebin: Provide recycle bin to reserve dropped objects to prevent mistake. DDL event tracking: Tracking, recording, publishing and subscribing DDL operations.  "},{"id":15,"href":"/_includes/","title":"Includes","parent":"Welcome to Redrock Documentation","content":""},{"id":16,"href":"/_includes/include-page/","title":"Include Page","parent":"Includes","content":"Example page include\n Example Shortcode\nShortcode used in an include page.     Head 1 Head 2 Head 3     1 2 3    "},{"id":17,"href":"/tags/","title":"Tags","parent":"Welcome to Redrock Documentation","content":""},{"id":18,"href":"/","title":"Welcome to Redrock Documentation","parent":"","content":"Redrock is an object-relational database management system (ORDBMS) based on PostgreSQL, developed by the PostgreSQL Global Development Group. It is intentionally designed as an enterprise grade and cloud native database.\nGetting Started   Feature overview   Undo   Log record for roll back modified data and transactions.  Multitenant   Single database instance runs on a server and serves multiple tenants.  Network based tablespace   Devide computing and storage functions in database through network based tablespace.   Multithread   The multithreaded database model enables server processes to execute as operating system threads in separate address spaces.  Recyclebin   Provide recycle bin to reserve dropped objects to prevent mistake.  DDL event tracking   Tracking, recording, publishing and subscribing DDL operations.   "}]